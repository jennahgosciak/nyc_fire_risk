{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jennahgosciak/nyc_fire_risk/blob/main/00_data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1iob6hhzqBo",
    "outputId": "de0ac75a-2af0-489b-ad9a-583476fb2520"
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import requests\n",
    "import calendar\n",
    "import geopandas as gpd\n",
    "import os.path as os\n",
    "import scipy.stats\n",
    "import seaborn.palettes\n",
    "import seaborn.utils\n",
    "import sys\n",
    "from census import Census\n",
    "from us import states\n",
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sklearn modules\n",
    "import sklearn\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "root= r\"C:/Users/Jennah/Desktop/Code/nyc_fire_risk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "* Load analysis data, created in 00_data_processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(os.join(root, \"data/analysis_file.csv\"), index_col = 0)\n",
    "df.head()\n",
    "\n",
    "nacols= df.columns[df.isna().any()]\n",
    "# use 0 imputation\n",
    "df[[x + \"_na\" for x in nacols]] = df[nacols].apply(lambda x: np.where(\n",
    "                                        x.isna() | np.isinf(x), 1, 0))\n",
    "df[[x + \"_na\" for x in nacols]]\n",
    "df[nacols]= df[nacols].apply(lambda x: np.where(\n",
    "                    x.isna() | np.isinf(x), 1, 0))\n",
    "\n",
    "assert all([(df.loc[(df[nacols[i]] == 0), nacols[i]+\"_na\"] == 0).all() for i in range(len(nacols))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score with logistic regression: 0.10623105135275401\n"
     ]
    }
   ],
   "source": [
    "# set x and y and split data for test/train\n",
    "X= df.loc[:, df.columns[df.columns != \"vacate_ind\"]]\n",
    "y= df.loc[:, \"vacate_ind\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 999)\n",
    "# naively apply logistic regression\n",
    "lm=linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "print(\"\\nScore with logistic regression:\", lm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996662548109014"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# learn model\n",
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9964654964282162\n"
     ]
    }
   ],
   "source": [
    "# what is average w different random states\n",
    "OS=[]\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = i)    \n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train,y_train)\n",
    "    OS.append(dt.score(X_test,y_test))\n",
    "print(np.mean(OS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9959397449783121\n"
     ]
    }
   ],
   "source": [
    "# what is average w same random states, but different max depth values\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3,random_state=999)\n",
    "\n",
    "depths = range(1, 20)\n",
    "OS= []\n",
    "AUC_OS= []\n",
    "for i in depths:\n",
    "    dt = DecisionTreeClassifier(random_state = 999, max_depth = i)\n",
    "    dt.fit(X_train,y_train)\n",
    "    # use both score and roc auc\n",
    "    OS.append(dt.score(X_test,y_test))\n",
    "    pred=dt.predict_proba(X_test)[:,1]\n",
    "    AUC_OS.append(average_precision_score(np.array(y_test),pred))\n",
    "    \n",
    "print(np.mean(OS))\n",
    "print(np.mean(AUC_OS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since the data is unbalanced, it makes sense to use the precision recall curve**\n",
    "\n",
    "Also, we are more interested in positive outcome (e.g., a fire vacate order) than a negative outcome\n",
    "* Precision: what proportion of positive identifications was actually correct?\n",
    "* Recall: what proportion of actual positives was identified correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS AUC 0.3950147521533366\n"
     ]
    }
   ],
   "source": [
    "# what about using precision-recall area under the curve instead of the score\n",
    "AUC_OS=[]\n",
    "for i in range(10):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    dt=DecisionTreeClassifier()\n",
    "    dt.fit(X_train,y_train)\n",
    "    # probability of each class\n",
    "    pred=dt.predict_proba(X_test)[:,1] # predicted probability of y = 1\n",
    "    AUC_OS.append(average_precision_score(np.array(y_test),pred))\n",
    "print(\"OS AUC\",np.mean(AUC_OS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random chance 0.0046877320535374505\n"
     ]
    }
   ],
   "source": [
    "# random chance\n",
    "chance_OS=[]\n",
    "for i in range(10):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    # create 'prediction' vector that's the length of X_test vector\n",
    "    pred=np.random.random(len(X_test))\n",
    "    chance_OS.append(average_precision_score(np.array(y_test.apply(int)),pred))\n",
    "print(\"Random chance\", np.mean(chance_OS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMorEa7Z8ODUCEPTOlT1br+",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "nyc fire risk",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
